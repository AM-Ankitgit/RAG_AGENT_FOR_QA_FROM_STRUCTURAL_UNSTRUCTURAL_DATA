{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic.v1 import BaseModel\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "# os.getenv('GROQ_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "# ollama_model  = ChatGroq(model=\"llama3.3-8b-8192\", temperature=0,api_key=\"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\") \n",
    "# ollama_model  = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "# ollama_model = ChatGroq(model=\"llama2-13b\", temperature=0)\n",
    "# ollama_model = ChatGroq(model=\"oasst-sft-4-pythia-12b\", temperature=0)\n",
    "\n",
    "# ollama_model = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0,api_key=\"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\")\n",
    "# os.getenv('GROQ_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "# ollama_model = HuggingFaceEndpoint(\n",
    "#     repo_id=\"meta-llama/Llama-3.3-70B-Instruct\", #llm model\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "#     huggingfacehub_api_token=\"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\"\n",
    "    \n",
    "# )\n",
    "\n",
    "# meta-llama/Llama-3.3-70B-Instruct\n",
    "# HuggingFaceH4/zephyr-7b-beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sql database\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model  = ChatOpenAI(model_name=\"gpt-3.5-turbo\",api_key=api_key)\n",
    "\n",
    "# ollama_model  = ChatOpenAI(model_name=\"gpt-4o-mini\",api_key=api_key)\n",
    "\n",
    "ollama_model.invoke('hi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mysql_uri = 'mysql+mysqlconnector://root:AnkitBW123#@localhost:3306/my_database'\n",
    "\n",
    "# from langchain_community.utilities import SQLDatabase\n",
    "# db = SQLDatabase.from_uri(mysql_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Open a local file in binary write mode\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        # Write the content of the response (the file) to the local file\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "db = SQLDatabase.from_uri(\"sqlite:////home/tinkerspace/AIML/AdvanceRag_With_Multiple_DataSources/RAG_AGENT_FOR_QA_FROM_STRUCTURAL_UNSTRUCTURAL_DATA/data/Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check access of databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(\"SELECT * FROM Album\")\n",
    "# database successfully connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the peformance of the llm model for the sql query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role = \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\n",
    "    Question: {question}\\n\n",
    "    SQL Query: {query}\\n\n",
    "    SQL Result: {result}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from operator import itemgetter\n",
    "\n",
    "from pydantic.v1 import BaseModel\n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "\n",
    "\n",
    "write_query = create_sql_query_chain(\n",
    "    ollama_model, db)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    system_role)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "answer = answer_prompt | ollama_model | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"show all the table name\"\n",
    "response = chain.invoke({\"question\": message})\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['OPENAI_API_KEY'] = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# print(os.getenv(\"OPEN_AI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstalling pydantic-2.10.2:\n",
    "# Uninstalling langchain-openai-0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # Define your Hugging Face API endpoint and token\n",
    "# api_url = \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# api_token = \"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\"\n",
    "\n",
    "# # Prepare the headers and the request data\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {api_token}\",\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "# # Define the input prompt and parameters\n",
    "# data = {\n",
    "#     \"inputs\": \"Translate the following English text to French: Hello, how are you?\",\n",
    "#     \"parameters\": {\n",
    "#         \"max_new_tokens\": 512,\n",
    "#         \"do_sample\": False,\n",
    "#         \"repetition_penalty\": 1.03\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Send the request to the Hugging Face API\n",
    "# response = requests.post(api_url, json=data, headers=headers)\n",
    "\n",
    "# # Print the result\n",
    "# if response.status_code == 200:\n",
    "#     print(response.json())  # The response will contain the generated text\n",
    "# else:\n",
    "#     print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
